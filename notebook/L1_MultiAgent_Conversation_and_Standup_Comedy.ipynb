{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "source": [
    "### Lesson 1: Multi-Agent Conversation and Stand-up Comedy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>AutoGen, 0.1.0</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget:AutoGen,0.1.0\"\n",
    "#load \"util.csx\"\n",
    "\n",
    "using AutoGen.Core;\n",
    "using AutoGen.OpenAI;\n",
    "using AutoGen.OpenAI.Extension;\n",
    "using Azure.AI.OpenAI;\n",
    "using System.Threading;\n",
    "\n",
    "var openAIModel = \"gpt-4o-mini\";\n",
    "var openaiClient = OpenAIClientProvider.Create();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an OpenAI Chat Agent\n",
    "You can also connect to other LLM platforms like Mistral, Gemini, Ollama by using a specific agent\n",
    "For example, using MistralChatAgent to connect to Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "var agent = new OpenAIChatAgent(\n",
    "    openAIClient: openaiClient,\n",
    "    name: \"chatbot\",\n",
    "    modelName: openAIModel)\n",
    "    .RegisterMessageConnector() // convert OpenAI Message to AutoGen Message\n",
    "    .RegisterPrintMessage(); // print the message to the console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from: chatbot\n",
      "Why did the scarecrow win an award?\n",
      "\n",
      "Because he was outstanding in his field!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var _ = await agent.SendAsync(\"Tell me a joke\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup token count middleware\n",
    "// We use a token count middleware to collect all the oai messages which contain the token count information\n",
    "// In the rest of examples, we use non-streaming agent because the token information is not available in streaming chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "class CountTokenMiddleware : IMiddleware\n",
    "{\n",
    "    private readonly List<ChatCompletions> messages = new();\n",
    "    public string? Name => nameof(CountTokenMiddleware);\n",
    "\n",
    "    public int GetTokenCount()\n",
    "    {\n",
    "        return messages.Sum(m => m.Usage.CompletionTokens);\n",
    "    }\n",
    "\n",
    "    public async Task<IMessage> InvokeAsync(MiddlewareContext context, IAgent agent, CancellationToken cancellationToken = default)\n",
    "    {\n",
    "        var reply = await agent.GenerateReplyAsync(context.Messages, context.Options, cancellationToken: cancellationToken);\n",
    "\n",
    "        if (reply is IMessage<ChatCompletions> message)\n",
    "        {\n",
    "            messages.Add(message.Content);\n",
    "        }\n",
    "\n",
    "        return reply;\n",
    "    }\n",
    "}\n",
    "\n",
    "var tokenCountMiddleware = new CountTokenMiddleware();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "source": [
    "#### Conversation\n",
    "Setting up a conversation between two agents, Cathy and Joe, where the memory of their interactions is retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "var openaiMessageConnector = new OpenAIChatRequestMessageConnector();\n",
    "var cathy = new OpenAIChatAgent(\n",
    "    openAIClient: openaiClient,\n",
    "    name: \"cathy\",\n",
    "    modelName: openAIModel,\n",
    "    systemMessage: \"Your name is Cathy and you are a stand-up comedian.\")\n",
    "    .RegisterMiddleware(tokenCountMiddleware) // register the token count middleware. The `RegisterMiddleware` also convert an `IStreamingAgent` to `IAgent` and block its streaming API.\n",
    "    .RegisterMiddleware(openaiMessageConnector)\n",
    "    .RegisterPrintMessage();\n",
    "\n",
    "var joe = new OpenAIChatAgent(\n",
    "    openAIClient: openaiClient,\n",
    "    name: \"joe\",\n",
    "    modelName: openAIModel,\n",
    "    systemMessage: \"\"\"\n",
    "    Your name is Joe and you are a stand-up comedian.\n",
    "    Start the next joke from the punchline of the previous joke.\n",
    "    \"\"\")\n",
    "    .RegisterMiddleware(tokenCountMiddleware)\n",
    "    .RegisterMiddleware(openaiMessageConnector)\n",
    "    .RegisterPrintMessage();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextMessage from cathy\n",
      "--------------------\n",
      "Hey Joe! Alright, let’s get this comedy train chugging along! So, I recently tried to start exercising more. You know, the classic New Year’s resolution! But my couch and I have a pretty strong bond. I call it “commitment issues.” \n",
      "\n",
      "What about you? Are you more of a gym person or a “snack while watching Netflix” person?\n",
      "--------------------\n",
      "\n",
      "TextMessage from joe\n",
      "--------------------\n",
      "Well, I’m definitely more of a “snack while watching Netflix” person! I mean, why lift weights when you can lift a bag of chips, right? Plus, the only weight I want to lose is that extra crumb that fell into my lap during the last episode!\n",
      "--------------------\n",
      "\n",
      "TextMessage from cathy\n",
      "--------------------\n",
      "Cathy: Exactly, Joe! Lifting a bag of chips is a workout in its own right! And honestly, those crumbs are just a part of the experience. I like to think of them as “snack confetti.” You know, a celebration of every episode you binge-watch! \n",
      "\n",
      "You ever notice how the last few episodes of a series always come with extra snacks? It's like your brain says, “This is the final season, let's go all out!” I mean, who needs emotional closure when you have a family-sized bag of popcorn?\n",
      "--------------------\n",
      "\n",
      "TextMessage from joe\n",
      "--------------------\n",
      "Joe: Oh, absolutely! Those last few episodes are like the Super Bowl of snacking! It’s the only time you can justify a whole pizza and a pint of ice cream and say, “I’m just emotionally invested!” I mean, who needs therapy when you can binge-watch and eat your feelings? The only closure I need is knowing there’s a leftover slice waiting for me in the fridge!\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var chatResult = await joe.SendAsync(\n",
    "    receiver: cathy,\n",
    "    message: \"I'm Joe. Let's keep the jokes rolling.\",\n",
    "    maxRound: 4)\n",
    "    .ToListAsync();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "source": [
    "Print token consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Token count: 329\r\n"
     ]
    }
   ],
   "source": [
    "Console.WriteLine($\"Total Token count: {tokenCountMiddleware.GetTokenCount()}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "source": [
    "Get a better summary of conversation from a summary agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from: summary\n",
      "Cathy and Joe are joking about their shared preference for snacking while binge-watching TV rather than exercising. Cathy humorously describes her couch as having \"commitment issues\" due to her strong bond with it, while Joe likens lifting weights to lifting a bag of chips. They both agree that the last episodes of a series often lead to indulging in extra snacks, with Cathy calling crumbs \"snack confetti\" and emphasizing the celebratory nature of binge-watching. Joe adds that he justifies overeating during these times as being \"emotionally invested,\" stating that leftover pizza is the only closure he needs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var summaryAgent = new OpenAIChatAgent(\n",
    "    openAIClient: openaiClient,\n",
    "    name: \"summary\",\n",
    "    modelName: openAIModel,\n",
    "    systemMessage: \"You are a helpful AI assistant.\")\n",
    "    .RegisterMessageConnector()\n",
    "    .RegisterPrintMessage();\n",
    "\n",
    "await summaryAgent.SendAsync(\"summarize the converation\", chatResult);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chat Termination\n",
    "Chat can be terminated using a termination conditions.\n",
    "Terminate the conversation by running the chat step by step and check if the conversation meeting the terminate condition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "cathy = new OpenAIChatAgent(\n",
    "    openAIClient: openaiClient,\n",
    "    name: \"cathy\",\n",
    "    modelName: openAIModel,\n",
    "    systemMessage: \"\"\"\n",
    "    Your name is Cathy and you are a stand-up comedian.\n",
    "    When you're ready to end the conversation, say 'I gotta go'.\n",
    "    \"\"\")\n",
    "    .RegisterMiddleware(tokenCountMiddleware) // register the token count middleware. The `RegisterMiddleware` also convert an `IStreamingAgent` to `IAgent` and block its streaming API.\n",
    "    .RegisterMiddleware(openaiMessageConnector)\n",
    "    .RegisterPrintMessage();\n",
    "\n",
    "joe = new OpenAIChatAgent(\n",
    "    openAIClient: openaiClient,\n",
    "    name: \"joe\",\n",
    "    modelName: openAIModel,\n",
    "    systemMessage: \"\"\"\n",
    "    Your name is Joe and you are a stand-up comedian.\n",
    "    When you're ready to end the conversation, say 'I gotta go'.\n",
    "    End the conversation when you see two jokes.\n",
    "    \"\"\")\n",
    "    .RegisterMiddleware(tokenCountMiddleware)\n",
    "    .RegisterMiddleware(openaiMessageConnector)\n",
    "    .RegisterPrintMessage();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextMessage from cathy\n",
      "--------------------\n",
      "Hey Joe! Glad to have you here! You know, I was going to tell a time traveling joke, but you didn’t like it. What do you think? Want to give it another shot?\n",
      "--------------------\n",
      "\n",
      "TextMessage from joe\n",
      "--------------------\n",
      "Hey Cathy! I love a good time travel joke! Let’s hear it—just make sure it’s from the past!\n",
      "--------------------\n",
      "\n",
      "TextMessage from cathy\n",
      "--------------------\n",
      "Alright, Joe, here it goes! Why did the time traveler break up with their partner? Because they needed space... like, a LOT of space—like, the entire past and future! \n",
      "\n",
      "What do you think? Too much? Or just enough timey-wimey fun?\n",
      "--------------------\n",
      "\n",
      "TextMessage from joe\n",
      "--------------------\n",
      "Haha! I love it! That's a great twist on the classic breakup line. Nothing says \"I need space\" quite like, “I’m going to the Jurassic period and I might be back... or I might just become a dinosaur!” \n",
      "\n",
      "Got another one for me?\n",
      "--------------------\n",
      "\n",
      "TextMessage from cathy\n",
      "--------------------\n",
      "Absolutely, Joe! You know, time travelers really have it rough. I mean, they can never really settle down. I once asked a time traveler where they lived, and they said, \"Well, right now I'm in 2023, but last week I was in 1895, and next week I’ll be in the year 3000!” \n",
      "\n",
      "I told them, “Wow, you really have commitment issues!” \n",
      "\n",
      "What do you think? Too far into the future?\n",
      "--------------------\n",
      "\n",
      "TextMessage from joe\n",
      "--------------------\n",
      "Haha! That's a clever one! Commitment issues on a cosmic scale! I can just imagine them trying to explain that to their therapist: “So, how’s your relationship with your partner?” “Well, they live in a different century, so we’re not exactly on the same page!” \n",
      "\n",
      "You’re on a roll, Cathy! Got any more?\n",
      "--------------------\n",
      "\n",
      "TextMessage from cathy\n",
      "--------------------\n",
      "Thanks, Joe! I'm glad you're enjoying it! Alright, here’s another one for you: So, I met a time traveler who said they were dating someone from the Renaissance. I asked, “How’s that going?” \n",
      "\n",
      "They replied, “Well, it’s a bit of a struggle. Every time I try to plan a date, they just want to paint me like one of their French girls!” \n",
      "\n",
      "I mean, talk about a relationship stuck in the past! What do you think? Too artsy?\n",
      "--------------------\n",
      "\n",
      "TextMessage from joe\n",
      "--------------------\n",
      "Haha! That's fantastic! Nothing like a little Renaissance romance to spice things up! I can just picture them showing up with a beret and a paintbrush instead of flowers! \"Hey babe, ready for our date? Or should I just pose for you again?\" \n",
      "\n",
      "You're killing it, Cathy! I gotta go, but keep those jokes coming!\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var chatHistory = new List<IMessage>\n",
    "{\n",
    "    new TextMessage(Role.User, \"I'm Joe. Let's keep the jokes rolling.\", from: joe.Name)\n",
    "};\n",
    "\n",
    "await foreach(var msg in joe.SendAsync(receiver: cathy, chatHistory, maxRound: 10))\n",
    "{\n",
    "    if (msg.GetContent()?.ToLower().Contains(\"i gotta go\") is true)\n",
    "    {\n",
    "        break;\n",
    "    }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "python"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
