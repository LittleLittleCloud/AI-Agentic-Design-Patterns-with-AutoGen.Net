{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "source": [
    "### Lesson 1: Multi-Agent Conversation and Stand-up Comedy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>AutoGen, 0.0.16</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget:AutoGen\"\n",
    "\n",
    "using AutoGen.Core;\n",
    "using AutoGen.OpenAI;\n",
    "using AutoGen.OpenAI.Extension;\n",
    "using Azure.AI.OpenAI;\n",
    "using System.Threading;\n",
    "\n",
    "var openAIKey = Environment.GetEnvironmentVariable(\"OPENAI_API_KEY\") ?? throw new Exception(\"Please set the OPENAI_API_KEY environment variable.\");\n",
    "var openAIModel = \"gpt-3.5-turbo\";\n",
    "var openaiClient = new OpenAIClient(openAIKey);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an OpenAI Chat Agent\n",
    "You can also connect to other LLM platforms like Mistral, Gemini, Ollama by using a specific agent\n",
    "For example, using MistralChatAgent to connect to Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "var agent = new OpenAIChatAgent(\n",
    "    openAIClient: openaiClient,\n",
    "    name: \"chatbot\",\n",
    "    modelName: openAIModel)\n",
    "    .RegisterMessageConnector() // convert OpenAI Message to AutoGen Message\n",
    "    .RegisterPrintMessage(); // print the message to the console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from: chatbot\n",
      "Sure! Here's a joke for you:\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var _ = await agent.SendAsync(\"Tell me a joke\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup token count middleware\n",
    "// We use a token count middleware to collect all the oai messages which contain the token count information\n",
    "// In the rest of examples, we use non-streaming agent because the token information is not available in streaming chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "class CountTokenMiddleware : IMiddleware\n",
    "{\n",
    "    private readonly List<ChatCompletions> messages = new();\n",
    "    public string? Name => nameof(CountTokenMiddleware);\n",
    "\n",
    "    public int GetTokenCount()\n",
    "    {\n",
    "        return messages.Sum(m => m.Usage.CompletionTokens);\n",
    "    }\n",
    "\n",
    "    public async Task<IMessage> InvokeAsync(MiddlewareContext context, IAgent agent, CancellationToken cancellationToken = default)\n",
    "    {\n",
    "        var reply = await agent.GenerateReplyAsync(context.Messages, context.Options, cancellationToken: cancellationToken);\n",
    "\n",
    "        if (reply is IMessage<ChatCompletions> message)\n",
    "        {\n",
    "            messages.Add(message.Content);\n",
    "        }\n",
    "\n",
    "        return reply;\n",
    "    }\n",
    "}\n",
    "\n",
    "var tokenCountMiddleware = new CountTokenMiddleware();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "source": [
    "#### Conversation\n",
    "Setting up a conversation between two agents, Cathy and Joe, where the memory of their interactions is retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "var openaiMessageConnector = new OpenAIChatRequestMessageConnector();\n",
    "var cathy = new OpenAIChatAgent(\n",
    "    openAIClient: openaiClient,\n",
    "    name: \"cathy\",\n",
    "    modelName: openAIModel,\n",
    "    systemMessage: \"Your name is Cathy and you are a stand-up comedian.\")\n",
    "    .RegisterMiddleware(tokenCountMiddleware) // register the token count middleware. The `RegisterMiddleware` also convert an `IStreamingAgent` to `IAgent` and block its streaming API.\n",
    "    .RegisterMiddleware(openaiMessageConnector)\n",
    "    .RegisterPrintMessage();\n",
    "\n",
    "var joe = new OpenAIChatAgent(\n",
    "    openAIClient: openaiClient,\n",
    "    name: \"joe\",\n",
    "    modelName: openAIModel,\n",
    "    systemMessage: \"\"\"\n",
    "    Your name is Joe and you are a stand-up comedian.\n",
    "    Start the next joke from the punchline of the previous joke.\n",
    "    \"\"\")\n",
    "    .RegisterMiddleware(tokenCountMiddleware)\n",
    "    .RegisterMiddleware(openaiMessageConnector)\n",
    "    .RegisterPrintMessage();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextMessage from cathy\n",
      "--------------------\n",
      "Hey Joe! Glad you're ready for some laughs. So, I've been thinking about getting in shape. But then I remembered round is a shape, so I think I'm good for now. How about you, Joe?\n",
      "--------------------\n",
      "\n",
      "TextMessage from joe\n",
      "--------------------\n",
      "I'm definitely more of an oval shape myself. But hey, at least I can say I'm well-rounded!\n",
      "--------------------\n",
      "\n",
      "TextMessage from cathy\n",
      "--------------------\n",
      "Cathy\n",
      "--------------------\n",
      "\n",
      "TextMessage from joe\n",
      "--------------------\n",
      "Why did the tomato turn red? Because it saw Cathy ketchup!\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var chatResult = await joe.SendAsync(\n",
    "    receiver: cathy,\n",
    "    message: \"I'm Joe. Let's keep the jokes rolling.\",\n",
    "    maxRound: 4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "source": [
    "Print token consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Token count: 85\r\n"
     ]
    }
   ],
   "source": [
    "Console.WriteLine($\"Total Token count: {tokenCountMiddleware.GetTokenCount()}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "source": [
    "Get a better summary of conversation from a summary agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from: summary\n",
      "Joe and Cathy shared some light-hearted jokes with each other. Joe joked about being oval-shaped and well-rounded, while Cathy made a joke about round being a shape. Joe also made a pun involving Cathy's name and ketchup. Overall, they had a fun and playful exchange centered around humor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var summaryAgent = new OpenAIChatAgent(\n",
    "    openAIClient: openaiClient,\n",
    "    name: \"summary\",\n",
    "    modelName: openAIModel,\n",
    "    systemMessage: \"You are a helpful AI assistant.\")\n",
    "    .RegisterMessageConnector()\n",
    "    .RegisterPrintMessage();\n",
    "\n",
    "await summaryAgent.SendAsync(\"summarize the converation\", chatResult);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chat Termination\n",
    "Chat can be terminated using a termination conditions.\n",
    "Terminate the conversation by running the chat step by step and check if the conversation meeting the terminate condition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "cathy = new OpenAIChatAgent(\n",
    "    openAIClient: openaiClient,\n",
    "    name: \"cathy\",\n",
    "    modelName: openAIModel,\n",
    "    systemMessage: \"\"\"\n",
    "    Your name is Cathy and you are a stand-up comedian.\n",
    "    When you're ready to end the conversation, say 'I gotta go'.\n",
    "    \"\"\")\n",
    "    .RegisterMiddleware(tokenCountMiddleware) // register the token count middleware. The `RegisterMiddleware` also convert an `IStreamingAgent` to `IAgent` and block its streaming API.\n",
    "    .RegisterMiddleware(openaiMessageConnector)\n",
    "    .RegisterPrintMessage();\n",
    "\n",
    "joe = new OpenAIChatAgent(\n",
    "    openAIClient: openaiClient,\n",
    "    name: \"joe\",\n",
    "    modelName: openAIModel,\n",
    "    systemMessage: \"\"\"\n",
    "    Your name is Joe and you are a stand-up comedian.\n",
    "    When you're ready to end the conversation, say 'I gotta go'.\n",
    "    End the conversation when you see two jokes.\n",
    "    \"\"\")\n",
    "    .RegisterMiddleware(tokenCountMiddleware)\n",
    "    .RegisterMiddleware(openaiMessageConnector)\n",
    "    .RegisterPrintMessage();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextMessage from cathy\n",
      "--------------------\n",
      "Hey Joe! Glad you're ready for some laughs. Did you hear about the claustrophobic astronaut? He just needed a little space!\n",
      "--------------------\n",
      "\n",
      "TextMessage from joe\n",
      "--------------------\n",
      "Haha, that's a good one, Cathy! Here's one for you: Why couldn't the bicycle stand up by itself? Because it was two-tired!\n",
      "--------------------\n",
      "\n",
      "TextMessage from cathy\n",
      "--------------------\n",
      "Haha, I love it, Joe! Here's another one for you: Why did the math book look sad? Because it had too many problems!\n",
      "--------------------\n",
      "\n",
      "TextMessage from joe\n",
      "--------------------\n",
      "Haha, that's a good one, Cathy! Here's one for you: Why couldn't the leopard play hide and seek? Because he was always spotted!\n",
      "--------------------\n",
      "\n",
      "TextMessage from cathy\n",
      "--------------------\n",
      "Haha, that's a good one, Joe! Here's another one for you: Why did the scarecrow win an award? Because he was outstanding in his field!\n",
      "--------------------\n",
      "\n",
      "TextMessage from joe\n",
      "--------------------\n",
      "Haha, that's a classic one, Cathy! Here's one more for you: Why did the coffee file a police report? It got mugged!\n",
      "--------------------\n",
      "\n",
      "TextMessage from cathy\n",
      "--------------------\n",
      "Haha, I love it, Joe! Thanks for the laughs. I gotta go.\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var chatHistory = new List<IMessage>\n",
    "{\n",
    "    new TextMessage(Role.User, \"I'm Joe. Let's keep the jokes rolling.\", from: joe.Name)\n",
    "};\n",
    "var roundLeft = 10;\n",
    "while(roundLeft > 0)\n",
    "{\n",
    "    var replies = await joe.SendAsync(\n",
    "        receiver: cathy,\n",
    "        chatHistory,\n",
    "        maxRound: 1);\n",
    "\n",
    "    var reply = replies.Last();\n",
    "    if (reply.GetContent()?.ToLower().Contains(\"i gotta go\") is true)\n",
    "    {\n",
    "        break;\n",
    "    }\n",
    "    chatHistory.Add(reply);\n",
    "    roundLeft--;\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "python"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
