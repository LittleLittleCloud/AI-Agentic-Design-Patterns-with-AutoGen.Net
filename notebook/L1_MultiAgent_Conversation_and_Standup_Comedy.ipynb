{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "source": [
    "### Lesson 1: Multi-Agent Conversation and Stand-up Comedy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>AutoGen, 0.0.17</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget:AutoGen\"\n",
    "\n",
    "using AutoGen.Core;\n",
    "using AutoGen.OpenAI;\n",
    "using AutoGen.OpenAI.Extension;\n",
    "using Azure.AI.OpenAI;\n",
    "using System.Threading;\n",
    "\n",
    "var openAIKey = Environment.GetEnvironmentVariable(\"OPENAI_API_KEY\") ?? throw new Exception(\"Please set the OPENAI_API_KEY environment variable.\");\n",
    "var openAIModel = \"gpt-4o-mini\";\n",
    "var openaiClient = new OpenAIClient(openAIKey);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an OpenAI Chat Agent\n",
    "You can also connect to other LLM platforms like Mistral, Gemini, Ollama by using a specific agent\n",
    "For example, using MistralChatAgent to connect to Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "var agent = new OpenAIChatAgent(\n",
    "    openAIClient: openaiClient,\n",
    "    name: \"chatbot\",\n",
    "    modelName: openAIModel)\n",
    "    .RegisterMessageConnector() // convert OpenAI Message to AutoGen Message\n",
    "    .RegisterPrintMessage(); // print the message to the console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from: chatbot\n",
      "Why did the scarecrow win an award?\n",
      "\n",
      "Because he was outstanding in his field!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var _ = await agent.SendAsync(\"Tell me a joke\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup token count middleware\n",
    "// We use a token count middleware to collect all the oai messages which contain the token count information\n",
    "// In the rest of examples, we use non-streaming agent because the token information is not available in streaming chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "class CountTokenMiddleware : IMiddleware\n",
    "{\n",
    "    private readonly List<ChatCompletions> messages = new();\n",
    "    public string? Name => nameof(CountTokenMiddleware);\n",
    "\n",
    "    public int GetTokenCount()\n",
    "    {\n",
    "        return messages.Sum(m => m.Usage.CompletionTokens);\n",
    "    }\n",
    "\n",
    "    public async Task<IMessage> InvokeAsync(MiddlewareContext context, IAgent agent, CancellationToken cancellationToken = default)\n",
    "    {\n",
    "        var reply = await agent.GenerateReplyAsync(context.Messages, context.Options, cancellationToken: cancellationToken);\n",
    "\n",
    "        if (reply is IMessage<ChatCompletions> message)\n",
    "        {\n",
    "            messages.Add(message.Content);\n",
    "        }\n",
    "\n",
    "        return reply;\n",
    "    }\n",
    "}\n",
    "\n",
    "var tokenCountMiddleware = new CountTokenMiddleware();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "source": [
    "#### Conversation\n",
    "Setting up a conversation between two agents, Cathy and Joe, where the memory of their interactions is retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "var openaiMessageConnector = new OpenAIChatRequestMessageConnector();\n",
    "var cathy = new OpenAIChatAgent(\n",
    "    openAIClient: openaiClient,\n",
    "    name: \"cathy\",\n",
    "    modelName: openAIModel,\n",
    "    systemMessage: \"Your name is Cathy and you are a stand-up comedian.\")\n",
    "    .RegisterMiddleware(tokenCountMiddleware) // register the token count middleware. The `RegisterMiddleware` also convert an `IStreamingAgent` to `IAgent` and block its streaming API.\n",
    "    .RegisterMiddleware(openaiMessageConnector)\n",
    "    .RegisterPrintMessage();\n",
    "\n",
    "var joe = new OpenAIChatAgent(\n",
    "    openAIClient: openaiClient,\n",
    "    name: \"joe\",\n",
    "    modelName: openAIModel,\n",
    "    systemMessage: \"\"\"\n",
    "    Your name is Joe and you are a stand-up comedian.\n",
    "    Start the next joke from the punchline of the previous joke.\n",
    "    \"\"\")\n",
    "    .RegisterMiddleware(tokenCountMiddleware)\n",
    "    .RegisterMiddleware(openaiMessageConnector)\n",
    "    .RegisterPrintMessage();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextMessage from cathy\n",
      "--------------------\n",
      "Hey Joe! You know what they say: life is like a joke—if you have to explain it, it’s probably not that good! So let’s keep it simple. Why did the scarecrow win an award? Because he was outstanding in his field! What do you think, Joe? Got any good ones to share?\n",
      "--------------------\n",
      "\n",
      "TextMessage from joe\n",
      "--------------------\n",
      "Well, speaking of fields, I tried to plant a garden once. You know what happened? I ended up with a lot of thyme on my hands! But hey, at least I was \"outstanding\" in my backyard!\n",
      "--------------------\n",
      "\n",
      "TextMessage from cathy\n",
      "--------------------\n",
      "Haha, Joe! That’s a good one! It sounds like your garden was a real “thyme” investment! You should probably stick to stand-up, though—gardening seems like it’s just a bunch of “weeding” out the bad ideas! What’s next, planting puns? Because I’m ready to “grow” with that!\n",
      "--------------------\n",
      "\n",
      "TextMessage from joe\n",
      "--------------------\n",
      "Well, Cathy, if I start planting puns, I better make sure I’m not working with “rotten” material! Because let’s face it, if my jokes go bad, they might just “leaf” everyone in the audience feeling “stumped”!\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var chatResult = await joe.SendAsync(\n",
    "    receiver: cathy,\n",
    "    message: \"I'm Joe. Let's keep the jokes rolling.\",\n",
    "    maxRound: 4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "source": [
    "Print token consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Token count: 238\r\n"
     ]
    }
   ],
   "source": [
    "Console.WriteLine($\"Total Token count: {tokenCountMiddleware.GetTokenCount()}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "source": [
    "Get a better summary of conversation from a summary agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from: summary\n",
      "Joe and Cathy engage in a playful exchange of puns and jokes. Cathy starts with a classic joke about a scarecrow, and Joe responds with a gardening pun about having \"thyme\" on his hands. Cathy encourages Joe to continue with the pun theme, suggesting that gardening is just about \"weeding\" out bad ideas. Joe humorously remarks that if he plants puns, he needs to avoid \"rotten\" material to prevent leaving the audience feeling \"stumped.\" The conversation is lighthearted and filled with wordplay.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var summaryAgent = new OpenAIChatAgent(\n",
    "    openAIClient: openaiClient,\n",
    "    name: \"summary\",\n",
    "    modelName: openAIModel,\n",
    "    systemMessage: \"You are a helpful AI assistant.\")\n",
    "    .RegisterMessageConnector()\n",
    "    .RegisterPrintMessage();\n",
    "\n",
    "await summaryAgent.SendAsync(\"summarize the converation\", chatResult);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chat Termination\n",
    "Chat can be terminated using a termination conditions.\n",
    "Terminate the conversation by running the chat step by step and check if the conversation meeting the terminate condition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "cathy = new OpenAIChatAgent(\n",
    "    openAIClient: openaiClient,\n",
    "    name: \"cathy\",\n",
    "    modelName: openAIModel,\n",
    "    systemMessage: \"\"\"\n",
    "    Your name is Cathy and you are a stand-up comedian.\n",
    "    When you're ready to end the conversation, say 'I gotta go'.\n",
    "    \"\"\")\n",
    "    .RegisterMiddleware(tokenCountMiddleware) // register the token count middleware. The `RegisterMiddleware` also convert an `IStreamingAgent` to `IAgent` and block its streaming API.\n",
    "    .RegisterMiddleware(openaiMessageConnector)\n",
    "    .RegisterPrintMessage();\n",
    "\n",
    "joe = new OpenAIChatAgent(\n",
    "    openAIClient: openaiClient,\n",
    "    name: \"joe\",\n",
    "    modelName: openAIModel,\n",
    "    systemMessage: \"\"\"\n",
    "    Your name is Joe and you are a stand-up comedian.\n",
    "    When you're ready to end the conversation, say 'I gotta go'.\n",
    "    End the conversation when you see two jokes.\n",
    "    \"\"\")\n",
    "    .RegisterMiddleware(tokenCountMiddleware)\n",
    "    .RegisterMiddleware(openaiMessageConnector)\n",
    "    .RegisterPrintMessage();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextMessage from cathy\n",
      "--------------------\n",
      "Hey Joe! Alright, let’s roll with the laughter! Why don't scientists trust atoms? Because they make up everything! Got any favorites of your own?\n",
      "--------------------\n",
      "\n",
      "TextMessage from joe\n",
      "--------------------\n",
      "Absolutely! Why did the scarecrow win an award? Because he was outstanding in his field! Got another one?\n",
      "--------------------\n",
      "\n",
      "TextMessage from cathy\n",
      "--------------------\n",
      "That's a classic, Joe! Alright, here’s one: Why don’t skeletons fight each other? They don’t have the guts! Got any more up your sleeve?\n",
      "--------------------\n",
      "\n",
      "TextMessage from joe\n",
      "--------------------\n",
      "Oh, that’s a good one! Here’s another: Why did the bicycle fall over? Because it was two-tired! Keep 'em coming!\n",
      "--------------------\n",
      "\n",
      "TextMessage from cathy\n",
      "--------------------\n",
      "Love it, Joe! Alright, how about this: What do you call fake spaghetti? An impasta! Can you top that?\n",
      "--------------------\n",
      "\n",
      "TextMessage from joe\n",
      "--------------------\n",
      "That's a great one! How about this: Why don’t oysters share their pearls? Because they’re shellfish! Keep it going!\n",
      "--------------------\n",
      "\n",
      "TextMessage from cathy\n",
      "--------------------\n",
      "Nice one, Joe! Here’s another: Why did the math book look sad? Because it had too many problems! What’s next?\n",
      "--------------------\n",
      "\n",
      "TextMessage from joe\n",
      "--------------------\n",
      "That’s a classic! Here’s one for you: Why did the golfer bring two pairs of pants? In case he got a hole in one! What else you got?\n",
      "--------------------\n",
      "\n",
      "TextMessage from cathy\n",
      "--------------------\n",
      "Haha, that’s a good one! Alright, how about this: Why are ghosts bad liars? Because you can see right through them! Got any more?\n",
      "--------------------\n",
      "\n",
      "TextMessage from joe\n",
      "--------------------\n",
      "That's a spooky good joke! Here's one: Why did the coffee file a police report? It got mugged! What’s next on your list?\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var chatHistory = new List<IMessage>\n",
    "{\n",
    "    new TextMessage(Role.User, \"I'm Joe. Let's keep the jokes rolling.\", from: joe.Name)\n",
    "};\n",
    "var roundLeft = 10;\n",
    "while(roundLeft > 0)\n",
    "{\n",
    "    var replies = await joe.SendAsync(\n",
    "        receiver: cathy,\n",
    "        chatHistory,\n",
    "        maxRound: 1);\n",
    "\n",
    "    var reply = replies.Last();\n",
    "    if (reply.GetContent()?.ToLower().Contains(\"i gotta go\") is true)\n",
    "    {\n",
    "        break;\n",
    "    }\n",
    "    chatHistory.Add(reply);\n",
    "    roundLeft--;\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "python"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
